{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n[nltk_data] Downloading package stopwords to /home/dat/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /home/dat/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "from itertools import islice\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_time(t1, t2):\n",
    "    diff = t2 - t1\n",
    "    mins = int(diff / 60)\n",
    "    secs = round(diff % 60, 3)\n",
    "    return str(mins) + \" mins and \" + str(secs) + \" seconds\"\n",
    "\n",
    "def clean_str(sentence):\n",
    "    # Remove HTML\n",
    "    review_text = BeautifulSoup(sentence, features=\"html.parser\").text\n",
    "    # Remove non-letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z\\s\\s+]\", \"\", review_text).strip()\n",
    "    return letters_only\n",
    "\n",
    "def convert_plain_to_csv(text_file, csv_file):\n",
    "    t0 = time.time()\n",
    "    with open(text_file, \"r\") as f1, open(csv_file, \"w\") as f2:\n",
    "        i = 0\n",
    "        f2.write(\"productId,score,summary,text\\n\")\n",
    "        while True:\n",
    "            next_n_lines = list(islice(f1, 9))  # read 9 line\n",
    "            if not next_n_lines:\n",
    "                break\n",
    "\n",
    "            output_line = \"\"\n",
    "            for line in next_n_lines:\n",
    "                if \"product/productId:\" in line:\n",
    "                    output_line += line.split(\":\")[1].strip() + \",\"\n",
    "                elif \"review/score:\" in line:\n",
    "                    output_line += line.split(\":\")[1].strip() + \",\"\n",
    "                elif \"review/summary:\" in line:\n",
    "                    summary = clean_str(line.split(\":\")[1].strip()) + \",\"\n",
    "                    output_line += summary\n",
    "                elif \"review/text:\" in line:\n",
    "                    text = clean_str(line.split(\":\")[1].strip()) + \"\\n\"\n",
    "                    output_line += text\n",
    "\n",
    "            f2.write(output_line)\n",
    "\n",
    "            # print status\n",
    "            i += 1\n",
    "            if i % 10000 == 0:\n",
    "                print(i, \"reviews converted...\")\n",
    "\n",
    "    print(datetime.datetime.now(), \"- Converting completed in\", get_run_time(t0, time.time()))\n",
    "\n",
    "def get_data(file_name):\n",
    "    if os.path.exists(file_name):\n",
    "        print(\"-- \" + file_name + \" found locally\")\n",
    "        df = pd.read_csv(file_name)\n",
    "    return df\n",
    "\n",
    "def review_to_words(review):\n",
    "    # 1. Convert to lower case, split into individual words\n",
    "    words = review.lower().split()\n",
    "\n",
    "    # 2. Get english stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # 3. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    return \" \".join(meaningful_words)\n",
    "\n",
    "\n",
    "def cleaning_data(dataset, file_name):\n",
    "    t0 = time.time()\n",
    "    num_reviews = dataset[\"text\"].size\n",
    "    clean_train_reviews = []\n",
    "\n",
    "    # Loop over each review\n",
    "    for i in range(0, num_reviews):\n",
    "        # If the index is evenly divisible by 1000, print a message\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(\"Review\", i + 1, \"of\", num_reviews, \"\\n\")\n",
    "\n",
    "        productId = str(dataset[\"productId\"][i])\n",
    "        score = str(dataset[\"score\"][i])\n",
    "        summary = str(dataset[\"summary\"][i])\n",
    "        text = review_to_words(str(dataset[\"text\"][i]))\n",
    "\n",
    "        clean_train_reviews.append(productId + \",\" + score + \",\" + summary + \",\" + text + \"\\n\")\n",
    "\n",
    "    print(\"Writing clean train reviews...\")\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(\"productId,score,summary,text\\n\")\n",
    "        for review in clean_train_reviews:\n",
    "            f.write(\"%s\\n\" % review)\n",
    "\n",
    "    \n",
    "    print(datetime.datetime.now(), \"- Write file completed in\", get_run_time(t0, time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Pre-processing\n",
    "# \"\"\"\n",
    "# convert_plain_to_csv(\"finefoods.txt\", \"foods.csv\")\n",
    "\n",
    "# # Reading the Data\n",
    "# train = get_data(\"foods.csv\")\n",
    "# print(\"Data dimensions:\", train.shape)\n",
    "# print(\"List features:\", train.columns.values)\n",
    "\n",
    "# cleaning_data(train, \"clean_train_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from file\n",
    "reviews = pd.read_csv(\"clean_train_reviews.csv\", nrows=20000)\n",
    "# ignore all 3* reviews\n",
    "reviews = reviews[reviews[\"score\"] != 3]\n",
    "# positive sentiment = 4* or 5* reviews (sentriment = True)\n",
    "reviews[\"sentiment\"] = reviews[\"score\"] >= 4\n",
    "\n",
    "# X = reviews['text'].values.astype('U')\n",
    "X = reviews['text']\n",
    "y = reviews['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bow = MultinomialNB()\n",
    "naive_tfidf = MultinomialNB()\n",
    "svm_clf_bow = svm.SVC(kernel='linear', C=1)\n",
    "svm_clf_tfidf = svm.SVC(kernel='linear', C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nAverage accuracy across folds: 85.18%\n\nAverage F1 score across folds: 90.90%\n\nAverage Precision score across folds: 94.03%\n\nAverage Recall score across folds: 87.97%\n\nAverage Confusion Matrix across folds: \n [[ 409.4  172.4]\n [ 371.7 2717.5]]\n"
    }
   ],
   "source": [
    "ss = ShuffleSplit(n_splits=10, test_size=0.2)\n",
    "sm = SMOTE()\n",
    "accs = []\n",
    "f1s = []\n",
    "cms = []\n",
    "pres = []\n",
    "recs = []\n",
    "vect = CountVectorizer(analyzer=\"word\",\n",
    "                            preprocessor=None,\n",
    "                            stop_words=None,\n",
    "                            max_features=1000)\n",
    "\n",
    "for train_index, test_index in ss.split(X):\n",
    "\n",
    "    \n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index].values.astype('U'), X.iloc[test_index].values.astype('U')\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    Encoder = LabelEncoder() \n",
    "    y_train = Encoder.fit_transform (y_train) \n",
    "    y_test = Encoder.fit_transform (y_test)\n",
    "    \n",
    "    # Fit vectorizer and transform X train, then transform X test\n",
    "    X_train_vect = vect.fit_transform(X_train)\n",
    "    X_test_vect = vect.transform(X_test)\n",
    "    \n",
    "    # Oversample\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train_vect, y_train)\n",
    "    \n",
    "    # Fit Naive Bayes on the vectorized X with y train labels, \n",
    "    # then predict new y labels using X test\n",
    "    naive_bow.fit(X_train_res, y_train_res)\n",
    "    # save the model to disk\n",
    "    filename = 'naive_bow.sav'\n",
    "    pickle.dump(naive_bow, open(filename, 'wb'))\n",
    "\n",
    "    y_pred = naive_bow.predict(X_test_vect)\n",
    "    \n",
    "    # Determine test set accuracy and f1 score on this fold using the true y labels and predicted y labels\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred))\n",
    "    cms.append(confusion_matrix(y_test, y_pred))\n",
    "    pres.append(precision_score(y_test, y_pred))\n",
    "    recs.append(recall_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAverage accuracy across folds: {:.2f}%\".format(sum(accs) / len(accs) * 100))\n",
    "print(\"\\nAverage F1 score across folds: {:.2f}%\".format(sum(f1s) / len(f1s) * 100))\n",
    "print(\"\\nAverage Precision score across folds: {:.2f}%\".format(sum(pres) / len(pres) * 100))\n",
    "print(\"\\nAverage Recall score across folds: {:.2f}%\".format(sum(recs) / len(recs) * 100))\n",
    "print(\"\\nAverage Confusion Matrix across folds: \\n {}\".format(sum(cms) / len(cms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nAverage accuracy across folds: 83.49%\n\nAverage F1 score across folds: 89.53%\n\nAverage Precision score across folds: 95.85%\n\nAverage Recall score across folds: 83.99%\n\nAverage Confusion Matrix across folds: \n [[ 473.9  112.2]\n [ 494.  2590.9]]\n"
    }
   ],
   "source": [
    "ss = ShuffleSplit(n_splits=10, test_size=0.2)\n",
    "sm = SMOTE()\n",
    "accs = []\n",
    "f1s = []\n",
    "cms = []\n",
    "pres = []\n",
    "recs = []\n",
    "vect = TfidfVectorizer(analyzer=\"word\",\n",
    "                                preprocessor=None,\n",
    "                                stop_words=None,\n",
    "                                max_features=1000)\n",
    "\n",
    "for train_index, test_index in ss.split(X):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index].values.astype('U'), X.iloc[test_index].values.astype('U')\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    Encoder = LabelEncoder() \n",
    "    y_train = Encoder.fit_transform (y_train) \n",
    "    y_test = Encoder.fit_transform (y_test)\n",
    "    \n",
    "    # Fit vectorizer and transform X train, then transform X test\n",
    "    X_train_vect = vect.fit_transform(X_train)\n",
    "    X_test_vect = vect.transform(X_test)\n",
    "    \n",
    "    # Oversample\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train_vect, y_train)\n",
    "    \n",
    "    # Fit Naive Bayes on the vectorized X with y train labels, \n",
    "    # then predict new y labels using X test\n",
    "    naive_tfidf.fit(X_train_res, y_train_res)\n",
    "    # save the model to disk\n",
    "    filename = 'naive_tfidf.sav'\n",
    "    pickle.dump(naive_tfidf, open(filename, 'wb'))\n",
    "\n",
    "    y_pred = naive_tfidf.predict(X_test_vect)\n",
    "    \n",
    "    # Determine test set accuracy and f1 score on this fold using the true y labels and predicted y labels\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred))\n",
    "    cms.append(confusion_matrix(y_test, y_pred))\n",
    "    pres.append(precision_score(y_test, y_pred))\n",
    "    recs.append(recall_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAverage accuracy across folds: {:.2f}%\".format(sum(accs) / len(accs) * 100))\n",
    "print(\"\\nAverage F1 score across folds: {:.2f}%\".format(sum(f1s) / len(f1s) * 100))\n",
    "print(\"\\nAverage Precision score across folds: {:.2f}%\".format(sum(pres) / len(pres) * 100))\n",
    "print(\"\\nAverage Recall score across folds: {:.2f}%\".format(sum(recs) / len(recs) * 100))\n",
    "print(\"\\nAverage Confusion Matrix across folds: \\n {}\".format(sum(cms) / len(cms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nAverage accuracy across folds: 88.67%\n\nAverage F1 score across folds: 93.37%\n\nAverage Precision score across folds: 91.04%\n\nAverage Recall score across folds: 95.81%\n\nAverage Confusion Matrix across folds: \n [[ 328  288]\n [ 128 2927]]\n"
    }
   ],
   "source": [
    "# X = X.values.astype('U')\n",
    "# sm = SMOTE()\n",
    "vect = CountVectorizer(analyzer=\"word\",\n",
    "                            preprocessor=None,\n",
    "                            stop_words=None,\n",
    "                            max_features=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values.astype('U'), y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "svm_clf_bow.fit(X_train, y_train)\n",
    "# save the model to disk\n",
    "filename = 'svm_clf-bow.sav'\n",
    "pickle.dump(svm_clf_bow, open(filename, 'wb'))\n",
    "\n",
    "y_pred = svm_clf_bow.predict(X_test)\n",
    "\n",
    "accs =accuracy_score(y_test, y_pred)\n",
    "f1s = f1_score(y_test, y_pred)\n",
    "cms = confusion_matrix(y_test, y_pred)\n",
    "pres = precision_score(y_test, y_pred)\n",
    "recs = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nAverage accuracy across folds: {:.2f}%\".format(accs* 100))\n",
    "print(\"\\nAverage F1 score across folds: {:.2f}%\".format(f1s * 100))\n",
    "print(\"\\nAverage Precision score across folds: {:.2f}%\".format(pres* 100))\n",
    "print(\"\\nAverage Recall score across folds: {:.2f}%\".format(recs* 100))\n",
    "print(\"\\nAverage Confusion Matrix across folds: \\n {}\".format(cms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nAverage accuracy across folds: 89.70%\n\nAverage F1 score across folds: 94.05%\n\nAverage Precision score across folds: 90.55%\n\nAverage Recall score across folds: 97.84%\n\nAverage Confusion Matrix across folds: \n [[ 304  312]\n [  66 2989]]\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# X = X.values.astype('U')\n",
    "vect = TfidfVectorizer(analyzer=\"word\",\n",
    "                                preprocessor=None,\n",
    "                                stop_words=None,\n",
    "                                max_features=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values.astype('U'), y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "svm_clf_tfidf.fit(X_train, y_train)\n",
    "# save the model to disk\n",
    "filename = 'svm_clf_tfidf.sav'\n",
    "pickle.dump(svm_clf_tfidf, open(filename, 'wb'))\n",
    "\n",
    "y_pred = svm_clf_tfidf.predict(X_test)\n",
    "\n",
    "accs =accuracy_score(y_test, y_pred)\n",
    "f1s = f1_score(y_test, y_pred)\n",
    "cms = confusion_matrix(y_test, y_pred)\n",
    "pres = precision_score(y_test, y_pred)\n",
    "recs = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nAverage accuracy across folds: {:.2f}%\".format(accs* 100))\n",
    "print(\"\\nAverage F1 score across folds: {:.2f}%\".format(f1s * 100))\n",
    "print(\"\\nAverage Precision score across folds: {:.2f}%\".format(pres* 100))\n",
    "print(\"\\nAverage Recall score across folds: {:.2f}%\".format(recs* 100))\n",
    "print(\"\\nAverage Confusion Matrix across folds: \\n {}\".format(cms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senten = [\n",
    "        'Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".',\n",
    "        'This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis\\' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.',\n",
    "        'Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.',\n",
    "        'It is good',\n",
    "        'It is bad',\n",
    "        'My cats have been happily eating Felidae Platinum for more than two years. I just got a new bag and the shape of the food is different. They tried the new food when I first put it in their bowls and now the bowls sit full and the kitties will not touch the food. I\\'ve noticed similar reviews related to formula changes in the past. Unfortunately, I now need to find a new food that my cats will eat.',\n",
    "        'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.',\n",
    "        'If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.',\n",
    "        'this is a nice',\n",
    "        'it is tasty'\n",
    "    ]\n",
    "\n",
    "sentences = []\n",
    "for x in senten:\n",
    "    se1= clean_sentence(x)\n",
    "    se2 = review_to_words(se1)\n",
    "    sentences.append(se2)\n",
    "\n",
    "check_lst = vectorizer.transform(sentences).toarray()\n",
    "# print(vectorizer.fit(sentences).tokenizer)\n",
    "# print(check_lst.reshape(2,100))\n",
    "result = clf.predict(check_lst)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitvenvvenv37e49d2265f24821afe9230a2e9d5607",
   "display_name": "Python 3.6.10 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}