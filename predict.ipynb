{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to /home/dat/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /home/dat/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "from itertools import islice\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = pickle.load(open('model/lstm_model.sav', 'rb'))\n",
    "naive_bow_model = pickle.load(open('model/naive_bow.sav', 'rb'))\n",
    "naive_tfidf_model = pickle.load(open('model/naive_tfidf.sav', 'rb'))\n",
    "svm_bow_model = pickle.load(open('model/svm_clf-bow.sav', 'rb'))\n",
    "svm_tfidf_model = pickle.load(open('model/svm_clf_tfidf.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_time(t1, t2):\n",
    "    diff = t2 - t1\n",
    "    mins = int(diff / 60)\n",
    "    secs = round(diff % 60, 3)\n",
    "    return str(mins) + \" mins and \" + str(secs) + \" seconds\"\n",
    "\n",
    "def clean_str(sentence):\n",
    "    # Remove HTML\n",
    "    review_text = BeautifulSoup(sentence, features=\"html.parser\").text\n",
    "    # Remove non-letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z\\s\\s+]\", \"\", review_text).strip()\n",
    "    return letters_only\n",
    "\n",
    "\n",
    "\n",
    "def get_data(file_name):\n",
    "    if os.path.exists(file_name):\n",
    "        print(\"-- \" + file_name + \" found locally\")\n",
    "        df = pd.read_csv(file_name)\n",
    "    return df\n",
    "\n",
    "def review_to_words(review):\n",
    "    # 1. Convert to lower case, split into individual words\n",
    "    words = review.lower().split()\n",
    "\n",
    "    # 2. Get english stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # 3. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    return \" \".join(meaningful_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from file\n",
    "reviews = pd.read_csv(\"clean_train_reviews.csv\", nrows=20000)\n",
    "# ignore all 3* reviews\n",
    "reviews = reviews[reviews[\"score\"] != 3]\n",
    "# positive sentiment = 4* or 5* reviews (sentriment = True)\n",
    "reviews[\"sentiment\"] = reviews[\"score\"] >= 4\n",
    "\n",
    "# X = reviews['text'].values.astype('U')\n",
    "X = reviews['text']\n",
    "y = reviews['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_bow = CountVectorizer(analyzer=\"word\",\n",
    "                            preprocessor=None,\n",
    "                            stop_words=None,\n",
    "                            max_features=1000)\n",
    "\n",
    "vect_tfidf = TfidfVectorizer(analyzer=\"word\",\n",
    "                                preprocessor=None,\n",
    "                                stop_words=None,\n",
    "                                max_features=1000)\n",
    "\n",
    "tokenizer = Tokenizer(nb_words=20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_bow.fit(X.values.astype('U'))\n",
    "vect_tfidf.fit(X.values.astype('U'))\n",
    "tokenizer.fit_on_texts(X.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "senten = [\n",
    "        \"I think anyone who expected this to be exactly like gin was fooling themselves. Just as the description says it is like comparing a veggie burger to beef. The veggie can be good too if used correctly, but it will never be beef. I made an offhand virgin negroni using this, blutul sweet vermouth and Italian san bitter. Turned out freaking awesome. Made a gimlet with fresh squeezed lime juice, simple syrup and ritual. It also turned out awesome. Use it for mixing and it is amazing\",\n",
    "        \"Every year I take a month off of drinking to prepare for or recover from holiday indulgences. During these months, I have often felt that what I missed was not beer, wine, or spirits, per se, but the rituals surrounding those drinks - the mixing of the cocktail after work, or sharing a concoction with friends and family. And so, Ritual piqued my interest. I’ve used the Ritual Gin Alternative in virgin gimlets and g&ts, and find it a nice substitute. It’s worth thinking of it as Ritual would ask you to think about it: as a veggie burger is to a hamburger, Ritual is to gin. It has the same floral character of gin, though in place of the burn of the alcohol there is what I think is a mild capsaicin burn. The flavor and burn give this a complexity that is often missing in mocktails. I won’t be giving up gin on a permanent basis. It’s too delicious. But for Sober October, or for days when I need to wake up early to work or work out, I’ll happily sub this into my gin cocktail of choice\",\n",
    "        \"I've been a gin drinker for 40 years. I'll guessing I've tried 3-4 dozen of different gins from all over the world.. And yes gin does have a slight 'pine' taste, and aroma to it. Unfortunately this non alcoholic gin taste and smells like Pine Floor/Surface cleaner. Not that you would want to drink a Pine scented Cleaner, but I would imagine this is what it would taste like. They WAAAAY over did the pine 'essence' in this 'gin'.Even mixing it with tonic water and a generous squirt of lime doesn't hide the over the top pine flavoring. Maybe they over did the Juniper in this, IDK. I even made a G and T with half this, and half Tanqueray, but nope, even doing that couldn't save the drink.. I really wanted to find an alternative to regular gin. This isn't it though. Too bad. I'll give them 2 stars though, at least they tried and from reading other reviews some people seem to like it, not me though. Years ago I had a small batch 'craft' gin made in Massachusetts, this reminded me of that gin. Very 'piney', maybe this Ritual gin is is trying to copy small small batch distillers. Anyway taste is subjective.\"\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for x in senten:\n",
    "    se1= clean_str(x)\n",
    "    se2 = review_to_words(se1)\n",
    "    sentences.append(se2)\n",
    "\n",
    "check_lst_bow = vect_bow.transform(sentences).toarray()\n",
    "check_lst_tfidf = vect_tfidf.transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 1, 1])"
     },
     "metadata": {},
     "execution_count": 211
    }
   ],
   "source": [
    "naive_bow_model.predict(check_lst_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 1, 1])"
     },
     "metadata": {},
     "execution_count": 212
    }
   ],
   "source": [
    "naive_tfidf_model.predict(check_lst_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([False,  True, False])"
     },
     "metadata": {},
     "execution_count": 213
    }
   ],
   "source": [
    "svm_bow_model.predict(check_lst_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([False,  True,  True])"
     },
     "metadata": {},
     "execution_count": 214
    }
   ],
   "source": [
    "svm_tfidf_model.predict(check_lst_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = np.zeros((len(sentences), 600), dtype='int32')\n",
    "for i,sen in enumerate(sentences):\n",
    "    if i > 10:\n",
    "        break\n",
    "    # print(sen)\n",
    "    for j,word in enumerate(sen.split()):\n",
    "        try:\n",
    "            if j < 600 and not tokenizer.word_index[word]:\n",
    "                data[i, j] = tokenizer.word_index[word]\n",
    "            else: \n",
    "                data[i, j] = 0\n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1.],\n       [1.],\n       [1.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 216
    }
   ],
   "source": [
    "lstm_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitvenvvenvb2562dc476a04f9cac9510ed63e2ef42",
   "display_name": "Python 3.6.10 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}